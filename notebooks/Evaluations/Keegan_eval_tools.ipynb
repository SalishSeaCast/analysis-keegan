{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a little notebook that I am adding all of the functions I create. Hopefully, they will eventually be good enough to add to the real evaltools, but if they never get there than at least they will be useful to me. Obviously the single cell created here will have to be copied into a normal python script for this to work as an importable script. I am just using Jupyter as a convenient text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Functions used to quickly graph evaluation plots for multiple stations and regions.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import datetime as dt\n",
    "from salishsea_tools import evaltools as et, viz_tools\n",
    "import gsw \n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import cmocean as cmo\n",
    "import scipy.interpolate as sinterp\n",
    "import pickle\n",
    "import cmocean\n",
    "import json\n",
    "import f90nml\n",
    "from collections import OrderedDict\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "def load_Pheo_data(year,datadir='/ocean/eolson/MEOPAR/obs/WADE/ptools_data/ecology'):\n",
    "    ## duplicate Station/Date entries with different times seem to be always within a couple of hours, \n",
    "    # so just take the first (next cell)\n",
    "    dfTime=pd.read_excel('/ocean/eolson/MEOPAR/obs/WADE/WDE_Data/OlsonSuchyAllen_UBC_PDR_P003790-010721.xlsx',\n",
    "                        engine='openpyxl',sheet_name='EventDateTime')\n",
    "    test=dfTime.groupby(['FlightDate','SiteCode'])['TimeDown \\n(Local - PST or PDT)'].count()\n",
    "    # drop duplicate rows\n",
    "    dfTime.drop_duplicates(subset=['FlightDate','SiteCode'],keep='first',inplace=True)\n",
    "    print(dfTime.keys())\n",
    "    dfTime['dtPac']=[dt.datetime.combine(idate, itime) for idate, itime \\\n",
    "             in zip(dfTime['FlightDate'],dfTime['TimeDown \\n(Local - PST or PDT)'])]\n",
    "    dfTime['dtUTC']=[et.pac_to_utc(ii) for ii in dfTime['dtPac']]\n",
    "    # PROCESS STATION LOCATION INFO (based on Parker's code)\n",
    "    sta_fn='/ocean/eolson/MEOPAR/obs/WADE/WDE_Data/OlsonSuchyAllen_UBC_PDR_P003790-010721.xlsx'\n",
    "    sheetname='Site Info'\n",
    "    sta_df =pd.read_excel(sta_fn,engine='openpyxl',sheet_name=sheetname)\n",
    "    sta_df.dropna(how='any',subset=['Lat_NAD83 (deg / dec_min)','Long_NAD83 (deg / dec_min)','Station'],inplace=True)\n",
    "    sta_df = sta_df.set_index('Station')\n",
    "    # get locations in decimal degrees\n",
    "    for sta in sta_df.index:\n",
    "        lat_str = sta_df.loc[sta, 'Lat_NAD83 (deg / dec_min)']\n",
    "        lat_deg = float(lat_str.split()[0]) + float(lat_str.split()[1])/60\n",
    "        sta_df.loc[sta,'Lat'] = lat_deg\n",
    "        #\n",
    "        lon_str = sta_df.loc[sta, 'Long_NAD83 (deg / dec_min)']\n",
    "        lon_deg = float(lon_str.split()[0]) + float(lon_str.split()[1])/60\n",
    "        sta_df.loc[sta,'Lon'] = -lon_deg    \n",
    "    sta_df.pop('Lat_NAD83 (deg / dec_min)');\n",
    "    sta_df.pop('Long_NAD83 (deg / dec_min)');\n",
    "    fn='/ocean/eolson/MEOPAR/obs/WADE/WDE_Data/OlsonSuchyAllen_UBC_PDR_P003790-010721.xlsx'\n",
    "    sheetname='LabChlaPheo'\n",
    "    chlPheo =pd.read_excel(fn,engine='openpyxl',sheet_name=sheetname)\n",
    "    chlPheo.dropna(how='any',subset=['Date','Station','SamplingDepth'],inplace=True)\n",
    "    # average over replicates\n",
    "    chlPheo2=pd.DataFrame(chlPheo.groupby(['Date','Station','SamplingDepth'],as_index=False).mean())\n",
    "    # join to station info (lat/lon)\n",
    "    chlPheo3=pd.merge(left=sta_df,right=chlPheo2,how='right',\n",
    "                     left_on='Station',right_on='Station')\n",
    "    # join to date/time\n",
    "    dfTime['dtUTC']=[et.pac_to_utc(dt.datetime.combine(idate,itime)) for idate,itime in \\\n",
    "                    zip(dfTime['FlightDate'],dfTime['TimeDown \\n(Local - PST or PDT)'])]\n",
    "    dfTime2=dfTime.loc[:,['FlightDate','SiteCode','dtUTC']]\n",
    "    chlPheoFinal=pd.merge(left=chlPheo3,right=dfTime2,how='left',\n",
    "                          left_on=['Date','Station'],right_on=['FlightDate','SiteCode'])\n",
    "    #drop the 47 NA datetime values\n",
    "    chlPheoFinal.dropna(how='any',subset=['dtUTC'],inplace=True)\n",
    "    #Add extra columns for later use\n",
    "    chlPheoFinal['Z']=chlPheoFinal['SamplingDepth']\n",
    "    chlPheoFinal['Year']=[ii.year for ii in chlPheoFinal['dtUTC']]\n",
    "    chlPheoFinal['YD']=et.datetimeToYD(chlPheoFinal['dtUTC'])\n",
    "    chlPheoYear=pd.DataFrame(chlPheoFinal.loc[chlPheoFinal.Year==year])\n",
    "    return chlPheoYear\n",
    "    \n",
    "def interpCTDvar(sta,yr,yd,ztarget,ctdvar):\n",
    "    ctdlocs=(dfCTD.Station==sta)&(dfCTD.Year==yr)&(dfCTD.YD==yd)\n",
    "    if np.sum(ctdlocs)==0:\n",
    "        print(f'Warning: Station {sta}, Year {yr}, year day {yd} not found in dfCTD')\n",
    "        return np.nan\n",
    "    else:\n",
    "        val=np.interp(ztarget,dfCTD.loc[ctdlocs,['Z']].values.flatten(),\n",
    "                  dfCTD.loc[ctdlocs,[ctdvar]].values.flatten())\n",
    "        return val\n",
    "\n",
    "def load_WADE_data(year,datadir='/ocean/eolson/MEOPAR/obs/WADE/ptools_data/ecology'):\n",
    "    \"\"\" Returns a dataframe containing nutrient bottle data for a given year merged with station data\n",
    "    \"\"\"\n",
    "    dfSta=pickle.load(open(os.path.join(datadir,'sta_df.p'),'rb'))\n",
    "    dfBot=pickle.load(open(os.path.join(datadir,f'Bottles_{str(year)}.p'),'rb'))\n",
    "    df=pd.merge(left=dfSta,right=dfBot,how='right',\n",
    "             left_on='Station',right_on='Station')\n",
    "    try:\n",
    "        len(df.loc[pd.isnull(df['Latitude'])]) == 0\n",
    "    except:\n",
    "        pass\n",
    "        print('Warning!, Stations found without Latitude or Longitude value!')\n",
    "    try:\n",
    "        len(df) == len(dfBot)\n",
    "    except:\n",
    "        pass\n",
    "        print(f'Warning!, Merge completed incorrectly. length of bottle data = {len(dfBot)} length of merged data = {len(df)}')\n",
    "    # where no time is provided, set time to midday Pacific time = ~ 20:00 UTC\n",
    "    df['UTCDateTime']=[iiD+dt.timedelta(hours=20) if pd.isnull(iiU) \\\n",
    "                    else iiU for iiU,iiD in \\\n",
    "                    zip(df['UTCDateTime'],df['Date'])]\n",
    "    df.rename(columns={'UTCDateTime':'dtUTC','Latitude':'Lat','Longitude':'Lon'},inplace=True)\n",
    "    df['Z']=-1*df['Z']\n",
    "    df.head()\n",
    "    df['NO23']=df['NO3(uM)D']+df['NO2(uM)D'] # the model does not distinguish between NO2 and NO3\n",
    "    df['Amm']=df['NH4(uM)D']\n",
    "    df['Si']=df['SiOH4(uM)D']\n",
    "    df['Year']=[ii.year for ii in df['dtUTC']]\n",
    "    df['YD']=et.datetimeToYD(df['dtUTC'])\n",
    "    return(df)\n",
    "   \n",
    "    \n",
    "def load_CTD_data(year,datadir='/ocean/eolson/MEOPAR/obs/WADE/ptools_data/ecology'):\n",
    "    \"\"\" Returns a dataframe containing CTD data for a given year merged with station data\n",
    "    \"\"\"\n",
    "    dfSta=pickle.load(open(os.path.join(datadir,'sta_df.p'),'rb'))\n",
    "    dfCTD0=pickle.load(open(os.path.join(datadir,f'Casts_{str(year)}.p'),'rb'))\n",
    "    dfCTD=pd.merge(left=dfSta,right=dfCTD0,how='right',\n",
    "             left_on='Station',right_on='Station')\n",
    "    try:\n",
    "        dfCTD.groupby(['Station','Year','YD','Z']).count()==[1]\n",
    "    except:\n",
    "        pass\n",
    "        print('Only one cast per CTD station per day')\n",
    "    # where no time is provided, set time to midday Pacific time = ~ 20:00 UTC\n",
    "    dfCTD['dtUTC']=[iiD+dt.timedelta(hours=20) for iiD in dfCTD['Date']] #Does this mean it also has that flaw where we are not sure when the data was collected?\n",
    "    dfCTD.rename(columns={'Latitude':'Lat','Longitude':'Lon'},inplace=True)\n",
    "    dfCTD['Z']=-1*dfCTD['Z']\n",
    "    # Calculate Absolute (Reference) Salinity (g/kg) and Conservative Temperature (deg C) from \n",
    "    # Salinity (psu) and Temperature (deg C):\n",
    "    press=gsw.p_from_z(-1*dfCTD['Z'],dfCTD['Lat'])\n",
    "    dfCTD['SA']=gsw.SA_from_SP(dfCTD['Salinity'],press,\n",
    "                           dfCTD['Lon'],dfCTD['Lat'])\n",
    "    dfCTD['CT']=gsw.CT_from_t(dfCTD['SA'],dfCTD['Temperature'],press)\n",
    "    dfCTD['Year']=[ii.year for ii in dfCTD['dtUTC']]\n",
    "    dfCTD['YD']=et.datetimeToYD(dfCTD['dtUTC'])\n",
    "    return(dfCTD)\n",
    "\n",
    "def byDepth(ax,df,obsvar,modvar,lims):\n",
    "    ps=et.varvarPlot(ax,df,obsvar,modvar,'Z',(15,22),'z','m',('mediumseagreen','darkturquoise','navy'))\n",
    "    l=ax.legend(handles=ps)\n",
    "    ax.set_xlabel('Obs')\n",
    "    ax.set_ylabel('Model')\n",
    "    ax.plot(lims,lims,'k-',alpha=.5)\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.set_aspect(1)\n",
    "    return ps,l\n",
    "\n",
    "def byRegion(ax,df,datreg,obsvar,modvar,lims):\n",
    "    ps=[]\n",
    "    for ind, iregion in enumerate(df.Basin.unique()):\n",
    "        ax.plot(datreg[iregion]['Lon'], datreg[iregion]['Lat'],'.',\n",
    "                color = colors[ind], label=iregion)\n",
    "        ps0=et.varvarPlot(ax,datreg[iregion],obsvar,modvar,\n",
    "                        cols=(colors[ind],),lname=iregion)\n",
    "        ps.append(ps0)\n",
    "    l=ax.legend(handles=[ip[0][0] for ip in ps])\n",
    "    ax.set_xlabel('Obs')\n",
    "    ax.set_ylabel('Model')\n",
    "    ax.plot(lims,lims,'k-',alpha=.5)\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.set_aspect(1)\n",
    "    return ps,l\n",
    "\n",
    "def byStation(ax,df,datstat,region,obsvar,modvar,lims):\n",
    "    ps=[]\n",
    "    for ind, istation in enumerate(df[df['Basin'] == region].Station.unique()):\n",
    "        ax.plot(datstat[istation]['Lon'], datstat[istation]['Lat'],'.',\n",
    "                    color = colors[ind], label=istation)\n",
    "        ps0=et.varvarPlot(ax,datstat[istation],obsvar,modvar,\n",
    "                        cols=(colors[ind],),lname=istation)\n",
    "        ps.append(ps0)\n",
    "    l=ax.legend(title='Stations',title_fontsize=20,handles=[ip[0][0] for ip in ps])\n",
    "    ax.set_xlabel('Obs')\n",
    "    ax.set_ylabel('Model')\n",
    "    ax.plot(lims,lims,'k-',alpha=.5)\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.set_aspect(1)\n",
    "    return ps,l\n",
    "\n",
    "def bySeason(ax,seasons,obsvar,modvar,lims):\n",
    "    for axi in ax:\n",
    "        axi.plot(lims,lims,'k-')\n",
    "        axi.set_xlim(lims)\n",
    "        axi.set_ylim(lims)\n",
    "        axi.set_aspect(1)\n",
    "        axi.set_xlabel('Obs')\n",
    "        axi.set_ylabel('Model')\n",
    "    ps=et.varvarPlot(ax[0],seaons[0],obsvar,modvar,cols=('crimson','darkturquoise','navy'))\n",
    "    ax[0].set_title('Jan-Mar')\n",
    "    ps=et.varvarPlot(ax[1],seaons[1],obsvar,modvar,cols=('crimson','darkturquoise','navy'))\n",
    "    ax[1].set_title('Apr')\n",
    "    ps=et.varvarPlot(ax[2],seaons[2],obsvar,modvar,cols=('crimson','darkturquoise','navy'))\n",
    "    ax[2].set_title('May-Aug')\n",
    "    ps=et.varvarPlot(ax[3],seasons[3],obsvar,modvar,cols=('crimson','darkturquoise','navy'))\n",
    "    ax[3].set_title('Sep-Dec')\n",
    "    return \n",
    "\n",
    "def hist2d(ax,df,obsvar,modvar,lims,fontsize=12):\n",
    "    ax.plot((-250,250),(-250,250),'k-',alpha=.2)\n",
    "    ii=(~np.isnan(df[obsvar]))&(~np.isnan(df[modvar]))\n",
    "    counts, xedges, yedges, ps=ax.hist2d(df.loc[ii,[obsvar]].values.flatten(),\n",
    "                                      df.loc[ii,[modvar]].values.flatten(),bins=25*3,norm=LogNorm())\n",
    "    cb=fig.colorbar(ps,ax=ax,label='Count',shrink=0.5)\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.set_ylabel('Modeled',fontsize=fontsize)\n",
    "    ax.set_xlabel('Observed',fontsize=fontsize)\n",
    "    plt.tight_layout()\n",
    "    return ps  \n",
    "\n",
    "def bySeason_hist2d(ax,seasons,obsvar,modvar,lims):\n",
    "    for axj in ax:\n",
    "        for axi in axj:\n",
    "            axi.plot(lims,lims,'k-')\n",
    "            axi.set_xlim(lims)\n",
    "            axi.set_ylim(lims)\n",
    "            axi.set_aspect(1)\n",
    "            axi.set_xlabel('Obs')\n",
    "            axi.set_ylabel('Model')\n",
    "    jp=hist2d(seaons[0],ax[0][0],obsvar,modvar,lims)\n",
    "    ax[0][0].set_title('Jan-Mar')\n",
    "    jp=hist2d(seaons[1],ax[0][1],obsvar,modvar,lims)\n",
    "    ax[0][1].set_title('Apr')\n",
    "    jp=hist2d(seaons[2],ax[1][0],obsvar,modvar,lims)\n",
    "    ax[1][0].set_title('May-Aug')\n",
    "    jp=hist2d(seasons[3],ax[1][1],obsvar,modvar,lims)\n",
    "    ax[1][1].set_title('Sep-Dec')\n",
    "    return \n",
    "\n",
    "def ErrErr(df,fig,ax,obsvar1,modvar1,obsvar2,modvar2,lims1,lims2):\n",
    "    m=ax.scatter(df[modvar1]-df[obsvar1],df[modvar2]-df[obsvar2],c=df['Z'],s=1,cmap='gnuplot')\n",
    "    cb=fig.colorbar(m,ax=ax,label='Depth (m)')\n",
    "    ax.set_xlim(lims1)\n",
    "    ax.set_ylim(lims2)\n",
    "    ax.set_aspect((lims1[1]-lims1[0])/(lims2[1]-lims2[0]))\n",
    "    return m,cb\n",
    "\n",
    "def multi_depreg_graph(df,datyear,years,obsvar,modvar,phyvar_name,lims,figsize):\n",
    "    if type(years) == int:\n",
    "        fig,ax=plt.subplots(1,2,figsize=figsize)\n",
    "        ps,l=byDepth(ax[0],obsvar,modvar,lims,byyear=True,year=years)\n",
    "        ax[0].set_title(f'{phyvar_name} (g kg$^-1$) By Depth for {years}')\n",
    "        ps,l=byRegion(ax[1],obsvar,modvar,lims,year=years)\n",
    "        ax[1].set_title(f'{phyvar_name} (g kg$^-1$) By Region for {years}');\n",
    "    elif type(years) == list:\n",
    "        fig,ax=plt.subplots(len(years),2,figsize=figsize)\n",
    "        for d,Y in enumerate(years):\n",
    "            ps,l=byDepth(ax[d][0],obsvar,modvar,lims,byyear=True,year=Y)\n",
    "            ax[d][0].set_title(f'{phyvar_name} (g kg$^-1$) By Depth for {Y}')\n",
    "            ps,l=byRegion(ax[d][1],obsvar,modvar,lims,year=Y)\n",
    "            ax[d][1].set_title(f'{phyvar_name} (g kg$^-1$) By Region for {Y}');\n",
    "    # put a raise exception thing into this. \n",
    "    plt.tight_layout()\n",
    "        \n",
    "# This has been altered but it has not been finished or tested !!!!!!!!!!!!!!!\n",
    "def multi_enverr_graph(df,datyear,years,obsvar,modvar,envvar,envvar_name,figsize):\n",
    "    if type(years) == int:\n",
    "        fig,ax=plt.subplots(1,len(obsvar),figsize=figsize)\n",
    "        for a,(o,m) in enumerate(zip(obsvar,modvar)):\n",
    "            ps=ax[a].scatter(datyear[years][envvar],datyear[years][m]-datyear[years][o],c=datyear[years]['Z'],s=1,cmap='gnuplot') \n",
    "            cb=fig.colorbar(ps,ax=ax[a],label='Depth (m)')\n",
    "            ax[a].set_xlabel(f'Obs {envvar_name}',fontsize=12)\n",
    "            ax[a].set_ylabel(f'{o} Error ($\\mu$M)',fontsize=12)\n",
    "            ax[a].set_title(str(years))\n",
    "    elif type(years) == list:\n",
    "        fig,ax=plt.subplots(len(years),len(obsvar),figsize=figsize)\n",
    "        for d,Y in zip(range(len(years)),years):\n",
    "            for a,(o,m) in enumerate(zip(obsvar,modvar)):\n",
    "                ps=ax[d][a].scatter(datyear[Y][envvar],datyear[Y][m]-datyear[Y][o],c=datyear[Y]['Z'],s=1,cmap='gnuplot') \n",
    "                cb=fig.colorbar(ps,ax=ax[d][a],label='Depth (m)')\n",
    "                ax[d][a].set_xlabel(f'Obs {envvar_name}',fontsize=12)\n",
    "                ax[d][a].set_ylabel(f'{o} Error ($\\mu$M)',fontsize=12)\n",
    "                ax[d][a].set_title(str(Y))\n",
    "    else:\n",
    "        raise(TypeError('years must be of type list or int'))\n",
    "    plt.tight_layout()\n",
    "        \n",
    "def multi_timerror_graph(df,datyear,years,obsvar,modvar,down,figsize):\n",
    "    fig,ax=plt.subplots(down,1,figsize=figsize)\n",
    "    for d,Y in zip(range(down),years):\n",
    "            m=ax[d].scatter(datyear[Y]['dtUTC'],datyear[Y][modvar]-datyear[Y][obsvar],s=8,cmap='gnuplot') \n",
    "            ax[d].set_xlabel(f'Date',fontsize=20)\n",
    "            ax[d].set_ylabel(f'{obsvar} Error ($\\mu$M)',fontsize=20)\n",
    "            ax[d].set_title(str(Y), fontsize=22)\n",
    "    plt.tight_layout()\n",
    "        \n",
    "def multi_station_graph(df,datstat,obsvar,modvar,regions,year,lims,down=6,figsize=(14,40)):\n",
    "    \"\"\" A function that creates a series of scatter plots and maps for each region\n",
    "        And shows the stations within each region colored on the graph and map. \n",
    "    \n",
    "    :arg df: A dataframe which data will be drawn from\n",
    "    :type :pandas dataframe\n",
    "    \n",
    "    :arg datstat: A dictionary which contains data on each seperate station\n",
    "    :type :dict\n",
    "    \n",
    "    :arg obsvar,modvar: The name of the observed and model variables you wish to compare to each other.\n",
    "    :type :string\n",
    "    \n",
    "    :are regions: The names of all of the basins you wish to look at \n",
    "    :type : list of strings\n",
    "    \n",
    "    :arg lims: A pair of values that will decide the range of the graph. Should always\n",
    "                    should always be larger than the maximum value of the variable.\n",
    "    :type : tuple\n",
    "    \n",
    "    :arg down: A number which should be equal to the number of regions you are looking at\n",
    "    :type : integer\n",
    "    \n",
    "    :arg figsize: a pair of values that decide the size of the entire figure\n",
    "    :type : tuple\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(down,2,figsize = figsize)\n",
    "    for d,r in zip(range(down),regions):\n",
    "        ps=byStation(ax[d][0],obsvar,modvar,lims,r,year)\n",
    "        ax[d][0].set_title(f'{obsvar} ($\\mu$M) in {r} by Station');\n",
    "\n",
    "        with nc.Dataset('/data/vdo/MEOPAR/NEMO-forcing/grid/bathymetry_201702.nc') as grid:\n",
    "            viz_tools.plot_coastline(ax[d][1], grid, coords = 'map',isobath=.1)\n",
    "\n",
    "        for ind, istation in enumerate(df[df['Basin'] == r].Station.unique()):\n",
    "            ax[d][1].plot(datstat[istation]['Lon'], datstat[istation]['Lat'],'.',\n",
    "                color = colors[ind], label=istation)\n",
    "        ax[d][1].set_ylim(47, 49)\n",
    "        ax[d][1].legend(bbox_to_anchor=[1,.6,0,0])\n",
    "        ax[d][1].set_xlim(-124, -122);\n",
    "        ax[d][1].set_title(f'Observation Locations for {r}');  \n",
    "\n",
    "def logt(x):\n",
    "    return np.log10(x+.001)\n",
    "\n",
    "def multi_timerror_graph(df,years,obsvar,modvar,figsize,):\n",
    "    if type(years) == int:\n",
    "        fig,ax=plt.subplots(1,1,figsize=figsize)\n",
    "        m=ax.scatter(datyear[years]['dtUTC'],datyear[years][modvar]-datyear[years][obsvar],s=8,cmap='gnuplot') \n",
    "        ax.set_xlabel(f'Date',fontsize=20)\n",
    "        ax.set_ylabel(f'{obsvar} Error ($\\mu$M)',fontsize=20)\n",
    "        ax.set_title(str(years), fontsize=22)\n",
    "        yearsFmt = mdates.DateFormatter('%d %b')\n",
    "        ax.xaxis.set_major_formatter(yearsFmt)\n",
    "    elif type(years) == list:\n",
    "        for d,Y in zip(range(down),years):\n",
    "                m=ax[d].scatter(datyear[Y]['dtUTC'],datyear[Y][modvar]-datyear[Y][obsvar],s=8,cmap='gnuplot') \n",
    "                ax[d].set_xlabel(f'Date',fontsize=20)\n",
    "                ax[d].set_ylabel(f'{obsvar} Error ($\\mu$M)',fontsize=20)\n",
    "                ax[d].set_title(str(Y), fontsize=22)\n",
    "                yearsFmt = mdates.DateFormatter('%d %b')\n",
    "                ax[d].xaxis.set_major_formatter(yearsFmt)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def multi_meanerr_graph(df,datyear,years,obsvar,modvar,down,figsize):\n",
    "    fig,ax=plt.subplots(down,1,figsize=figsize)\n",
    "    for d,Y in zip(range(down),years):\n",
    "            meanerr=datyear[Y].groupby(by='dtUTC').mean()\n",
    "            m=ax[d].plot(datyear[Y]['dtUTC'].unique(),meanerr[modvar]-meanerr[obsvar],'c-') \n",
    "            ax[d].set_xlabel(f'Date',fontsize=20)\n",
    "            ax[d].set_ylabel(f'{obsvar} Error ($\\mu$M)',fontsize=20)\n",
    "            ax[d].set_title(str(Y), fontsize=22)\n",
    "            yearsFmt = mdates.DateFormatter('%d %b')\n",
    "            ax[d].xaxis.set_major_formatter(yearsFmt)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def multi_timese_graph(df,years,obsvar,modvar,figsize):\n",
    "    if type(years) == int:\n",
    "        fig,ax=plt.subplots(1,1,figsize=figsize)\n",
    "        ps=tsertser_graph(ax,df,obsvar,modvar,dt.datetime(years,1,1),dt.datetime(years,12,31),'Z',(15,22),'z','m')\n",
    "        ax.legend(handles=ps,bbox_to_anchor=[1,.6,0,0])\n",
    "        ax.set_xlabel(f'Date',fontsize=20)\n",
    "        ax.set_ylabel(f'{obsvar} ($\\mu$M)',fontsize=20)\n",
    "        ax.set_title(str(years), fontsize=22)\n",
    "        yearsFmt = mdates.DateFormatter('%d %b')\n",
    "        ax.xaxis.set_major_formatter(yearsFmt)\n",
    "    elif type(years) == list:  \n",
    "        fig, ax=plt.subplots(len(years),1,figsize=figsize)\n",
    "        for d,Y in zip(range(len(years)),years):\n",
    "            ps=tsertser_graph(ax[d],df,obsvar,modvar,dt.datetime(Y,1,1),dt.datetime(Y,12,31),'Z',(15,22),'z','m')\n",
    "            ax[d].legend(handles=ps,bbox_to_anchor=[1,.6,0,0])\n",
    "            ax[d].set_xlabel(f'Date',fontsize=20)\n",
    "            ax[d].set_ylabel(f'{obsvar} ($\\mu$M)',fontsize=20)\n",
    "            ax[d].set_title(str(Y), fontsize=22)\n",
    "            yearsFmt = mdates.DateFormatter('%d %b')\n",
    "            ax[d].xaxis.set_major_formatter(yearsFmt)\n",
    "    else:\n",
    "        raise(TypeError('years must be of type list or int'))\n",
    "    plt.tight_layout()\n",
    "    \n",
    "#ready for evaltools\n",
    "def tsertser_graph(ax,df,obsvar,modvar,start_date,end_date,sepvar='',sepvals=([]),lname='',sepunits='',\n",
    "                  ocols=('blue','darkviolet','teal','green','deepskyblue'),\n",
    "                  mcols=('fuchsia','firebrick','orange','darkgoldenrod','maroon'),labels=''):\n",
    "    \"\"\" Creates timeseries by adding scatter plot to axes ax with df['dtUTC'] on x-axis, \n",
    "        df[obsvar] and df[modvar] on y axis, and colors taken from a listas determined from \n",
    "        df[sepvar] and a list of bin edges, sepvals\n",
    "    \"\"\"\n",
    "    if len(lname)==0:\n",
    "        lname=sepvar\n",
    "    ps=list()\n",
    "    if len(sepvals)==0:\n",
    "        obs0=_deframe(df.loc[(df['dtUTC'] >= start_date)&(df['dtUTC']<= end_date),[obsvar]])\n",
    "        mod0=_deframe(df.loc[(df['dtUTC'] >= start_date)&(df['dtUTC']<= end_date),[modvar]])\n",
    "        time0=_deframe(df.loc[(df['dtUTC'] >= start_date)&(df['dtUTC']<= end_date),['dtUTC']])\n",
    "        ps.append(ax.plot(time0,obs0,'.',color=ocols[0],label=f'Observed {lname}'))\n",
    "        ps.append(ax.plot(time0,mod0,'.',color=mcols[0],label=f'Modeled {lname}'))\n",
    "    else:\n",
    "        obs0=_deframe(df.loc[(df[obsvar]==df[obsvar])&(df[modvar]==df[modvar])&(df[sepvar]==df[sepvar])&(df['dtUTC'] >= start_date)&(df['dtUTC']<= end_date),[obsvar]])\n",
    "        mod0=_deframe(df.loc[(df[obsvar]==df[obsvar])&(df[modvar]==df[modvar])&(df[sepvar]==df[sepvar])&(df['dtUTC'] >= start_date)&(df['dtUTC']<= end_date),[modvar]])\n",
    "        time0=_deframe(df.loc[(df[obsvar]==df[obsvar])&(df[modvar]==df[modvar])&(df[sepvar]==df[sepvar])&(df['dtUTC'] >= start_date)&(df['dtUTC']<= end_date),['dtUTC']])\n",
    "        sep0=_deframe(df.loc[(df[obsvar]==df[obsvar])&(df[modvar]==df[modvar])&(df[sepvar]==df[sepvar])&(df['dtUTC'] >= start_date)&(df['dtUTC']<= end_date),[sepvar]])\n",
    "        sepvals=np.sort(sepvals)\n",
    "                # less than min case:\n",
    "        ii=0\n",
    "        iii=sep0<sepvals[ii]\n",
    "        if np.sum(iii)>0:\n",
    "            #ll=u'{} < {} {}'.format(lname,sepvals[ii],sepunits).strip()\n",
    "            if len(labels)>0:\n",
    "                ll=labels[0]\n",
    "            else:\n",
    "                ll=u'{} $<$ {} {}'.format(lname,sepvals[ii],sepunits).strip()\n",
    "            p0,=ax.plot(time0[iii],obs0[iii],'.',color=ocols[ii],label=f'Observed {ll}')\n",
    "            ps.append(p0)\n",
    "            p0,=ax.plot(time0[iii],mod0[iii],'.',color=mcols[ii],label=f'Modeled {ll}')\n",
    "            ps.append(p0)\n",
    "        # between min and max:\n",
    "        for ii in range(1,len(sepvals)):\n",
    "            iii=np.logical_and(sep0<sepvals[ii],sep0>=sepvals[ii-1])\n",
    "            if np.sum(iii)>0:\n",
    "                #ll=u'{} {} \\u2264 {} < {} {}'.format(sepvals[ii-1],sepunits,lname,sepvals[ii],sepunits).strip()\n",
    "                if len(labels)>0:\n",
    "                    ll=labels[ii]\n",
    "                else:\n",
    "                    ll=u'{} {} $\\leq$ {} $<$ {} {}'.format(sepvals[ii-1],sepunits,lname,sepvals[ii],sepunits).strip()\n",
    "            p0,=ax.plot(time0[iii],obs0[iii],'.',color=ocols[ii],label=f'Observed {ll}')\n",
    "            ps.append(p0)\n",
    "            p0,=ax.plot(time0[iii],mod0[iii],'.',color=mcols[ii],label=f'Modeled {ll}')\n",
    "            ps.append(p0)\n",
    "        # greater than max:\n",
    "        iii=sep0>=sepvals[ii]\n",
    "        if np.sum(iii)>0:\n",
    "            #ll=u'{} \\u2265 {} {}'.format(lname,sepvals[ii],sepunits).strip()\n",
    "            if len(labels)>0:\n",
    "                ll=labels[ii+1]\n",
    "            else:\n",
    "                ll=u'{} $\\geq$ {} {}'.format(lname,sepvals[ii],sepunits).strip()\n",
    "            p0,=ax.plot(time0[iii],obs0[iii],'.',color=ocols[ii+1],label=f'Observed {ll}')\n",
    "            ps.append(p0)\n",
    "            p0,=ax.plot(time0[iii],mod0[iii],'.',color=mcols[ii+1],label=f'Modeled {ll}')\n",
    "            ps.append(p0)\n",
    "    yearsFmt = mdates.DateFormatter('%d %b %y')\n",
    "    ax.xaxis.set_major_formatter(yearsFmt)\n",
    "    return ps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

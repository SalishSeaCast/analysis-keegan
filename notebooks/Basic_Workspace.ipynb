{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "import datetime as dt\n",
    "from salishsea_tools import evaltools as et, viz_tools\n",
    "import gsw \n",
    "import xarray as xr\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import cmocean as cmo\n",
    "import scipy.interpolate as sinterp\n",
    "import pickle\n",
    "import cmocean\n",
    "import json\n",
    "import f90nml\n",
    "from collections import OrderedDict\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "def load_obs_data(year,datadir='/ocean/eolson/MEOPAR/obs/WADE/ptools_data/ecology'):\n",
    "    \"\"\" Returns a dataframe containing nutrient bottle data for a given year merged with station data\n",
    "    \"\"\"\n",
    "    dfSta=pickle.load(open(os.path.join(datadir,'sta_df.p'),'rb'))\n",
    "    dfBot=pickle.load(open(os.path.join(datadir,f'Bottles_{str(year)}.p'),'rb'))\n",
    "    df=pd.merge(left=dfSta,right=dfBot,how='right',\n",
    "             left_on='Station',right_on='Station')\n",
    "    try:\n",
    "        len(df.loc[pd.isnull(df['Latitude'])]) == 0\n",
    "    except:\n",
    "        pass\n",
    "        print('Warning!, Stations found without Latitude or Longitude value!')\n",
    "    try:\n",
    "        len(df) == len(dfBot)\n",
    "    except:\n",
    "        pass\n",
    "        print(f'Warning!, Merge completed incorrectly. length of bottle data = {len(dfBot)} length of merged data = {len(df)}')\n",
    "    # where no time is provided, set time to midday Pacific time = ~ 20:00 UTC\n",
    "    df['UTCDateTime']=[iiD+dt.timedelta(hours=20) if pd.isnull(iiU) \\\n",
    "                    else iiU for iiU,iiD in \\\n",
    "                    zip(df['UTCDateTime'],df['Date'])]\n",
    "    df.rename(columns={'UTCDateTime':'dtUTC','Latitude':'Lat','Longitude':'Lon'},inplace=True)\n",
    "    df['Z']=-1*df['Z']\n",
    "    df.head()\n",
    "    df['NO23']=df['NO3(uM)D']+df['NO2(uM)D'] # the model does not distinguish between NO2 and NO3\n",
    "    df['Amm']=df['NH4(uM)D']\n",
    "    df['Si']=df['SiOH4(uM)D']\n",
    "    df['Year']=[ii.year for ii in df['dtUTC']]\n",
    "    df['YD']=et.datetimeToYD(df['dtUTC'])\n",
    "    return(df)\n",
    "    \n",
    "def load_CTD_data(year,datadir='/ocean/eolson/MEOPAR/obs/WADE/ptools_data/ecology'):\n",
    "    \"\"\" Returns a dataframe containing CTD data for a given year merged with station data\n",
    "    \"\"\"\n",
    "    dfSta=pickle.load(open(os.path.join(datadir,'sta_df.p'),'rb'))\n",
    "    dfCTD0=pickle.load(open(os.path.join(datadir,f'Casts_{str(year)}.p'),'rb'))\n",
    "    dfCTD=pd.merge(left=dfSta,right=dfCTD0,how='right',\n",
    "             left_on='Station',right_on='Station')\n",
    "    try:\n",
    "        dfCTD.groupby(['Station','Year','YD','Z']).count()==[1]\n",
    "    except:\n",
    "        pass\n",
    "        print('Only one cast per CTD station per day')\n",
    "    # where no time is provided, set time to midday Pacific time = ~ 20:00 UTC\n",
    "    dfCTD['dtUTC']=[iiD+dt.timedelta(hours=20) for iiD in dfCTD['Date']] #Does this mean it also has that flaw where we are not sure when the data was collected?\n",
    "    dfCTD.rename(columns={'Latitude':'Lat','Longitude':'Lon'},inplace=True)\n",
    "    dfCTD['Z']=-1*dfCTD['Z']\n",
    "    # Calculate Absolute (Reference) Salinity (g/kg) and Conservative Temperature (deg C) from \n",
    "    # Salinity (psu) and Temperature (deg C):\n",
    "    press=gsw.p_from_z(-1*dfCTD['Z'],dfCTD['Lat'])\n",
    "    dfCTD['SA']=gsw.SA_from_SP(dfCTD['Salinity'],press,\n",
    "                           dfCTD['Lon'],dfCTD['Lat'])\n",
    "    dfCTD['CT']=gsw.CT_from_t(dfCTD['SA'],dfCTD['Temperature'],press)\n",
    "    dfCTD['Year']=[ii.year for ii in dfCTD['dtUTC']]\n",
    "    dfCTD['YD']=et.datetimeToYD(dfCTD['dtUTC'])\n",
    "    return(dfCTD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxproc=4\n",
    "saveloc='/ocean/kflanaga/MEOPAR/202007_grid_data/'\n",
    "#Aloc='/data/eolson/MEOPAR/SS36runs/calcFiles/comparePhytoN/Area_240.nc'\n",
    "#meshpath='/ocean/eolson/MEOPAR/NEMO-forcing/grid/mesh_mask201702_noLPE.nc'\n",
    "#ptrcexpath='/results2/SalishSea/hindcast/05jul15/SalishSea_1h_20150705_20150705_ptrc_T.nc'\n",
    "plist=['Hoodsport','Twanoh','DabobBay','PointWells','CarrInlet','Hansville']\n",
    "varNameDict={'Hoodsport':'Hoodsport','Twanoh':'Twanoh','DabobBay':'DabobBay', 'PointWells':'PointWells',\n",
    "             'CarrInlet':'CarrInlet', 'Hansville':'Hansville'}\n",
    "t0=dt.datetime(2015,7,1)\n",
    "fdur=1 # length of each results file in days\n",
    "dirname='HC201905_2015'\n",
    "te=dt.datetime(2015,11,30)\n",
    "\n",
    "evars=('votemper','vosaline')\n",
    "\n",
    "\n",
    "def setup():\n",
    "    spath='/home/sallen/202007/202007C-p3/'\n",
    "    ffmt='%Y%m%d'\n",
    "    stencilp='SalishSea_1d_20150701_20151231_grid_T_{0}-{0}.nc'\n",
    "    # Ok, so this probably imputs the day month year as {0} and then the rest of the info goes into the next \n",
    "    # part. This filling in probably happens with the help of the the format. \n",
    "    # My only question now is why does it use carp? Should probably change to Grid. but why is grid filled up\n",
    "    # with stuff from carp t? must ask Elise. \n",
    "    fnum=int(((te-t0).days+1)/fdur)#fnum=18 # number of results files per run\n",
    "    runlen=fdur*fnum # length of run in days\n",
    "    fnames={'grid_T':dict(),'tempBase':dict()}\n",
    "    iits=t0\n",
    "    ind=0\n",
    "    while iits<=te:\n",
    "        iite=iits+dt.timedelta(days=(fdur-1)) \n",
    "        iitn=iits+dt.timedelta(days=fdur)\n",
    "        try:\n",
    "            iifstr=glob.glob(spath+stencilp.format(iits.strftime(ffmt),iite.strftime(ffmt)),recursive=True)[0]\n",
    "            fnames['grid_T'][ind]=iifstr\n",
    "        except:\n",
    "            print('file does not exist: '+spath+stencilp.format(iits.strftime(ffmt),iite.strftime(ffmt)))\n",
    "            raise\n",
    "        fnames['tempBase'][ind]=saveloc+'temp/grid'+iits.strftime(ffmt)+'_'+iite.strftime(ffmt)\n",
    "        iits=iitn\n",
    "        ind=ind+1\n",
    "    return spath,fnum,runlen,fnames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file does not exist: /home/sallen/202007/202007C-p3/SalishSea_1d_20150701_20151231_grid_T_20150901-20150901.nc\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-63ccd74074d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mspath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrunlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done setup'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-7e5044cdd9b0>\u001b[0m in \u001b[0;36msetup\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0miitn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miits\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfdur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0miifstr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstencilp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mfnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grid_T'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miifstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    spath,fnum,runlen,fnames=setup();\n",
    "    print('done setup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

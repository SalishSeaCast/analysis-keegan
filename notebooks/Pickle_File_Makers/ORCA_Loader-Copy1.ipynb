{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script loads and fixes up the moored data from the ORCA Buoys. PLEASE NOTE: this script has essentially been left in an unfinished state due to a change in workflow. All processing in of the ORCA data now happens in the analysis notebooks themselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import datetime as dt\n",
    "from salishsea_tools import evaltools as et, places, viz_tools\n",
    "import gsw \n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import cmocean as cmo\n",
    "import scipy.interpolate as sinterp\n",
    "from scipy import io\n",
    "import pickle\n",
    "import cmocean\n",
    "import json\n",
    "import f90nml\n",
    "from collections import OrderedDict\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "fs=16\n",
    "mpl.rc('xtick', labelsize=fs)\n",
    "mpl.rc('ytick', labelsize=fs)\n",
    "mpl.rc('legend', fontsize=fs)\n",
    "mpl.rc('axes', titlesize=fs)\n",
    "mpl.rc('axes', labelsize=fs)\n",
    "mpl.rc('figure', titlesize=fs)\n",
    "mpl.rc('font', size=fs)\n",
    "mpl.rc('font', family='sans-serif', weight='normal', style='normal')\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveloc='/ocean/kflanaga/MEOPAR/ORCAData'\n",
    "mooring='Twanoh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "orca_dict=io.loadmat(f'{saveloc}/{mooring}.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright. I am going to say that Btemp=temperature, Bdepth=depth, Bfluor= chlorophyll fluorescence\n",
    "Bsal=Salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData=list(zip(orca_dict['Btime'][1],orca_dict['Bdepth'][1],orca_dict['Btemp'][1],\n",
    "                 orca_dict['Bsal'][1],orca_dict['Bfluor'][1]))\n",
    "columns=['Decimal_days','Z','Temperature','Salinity','Chl']\n",
    "df=pd.DataFrame(newData,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding down the decimal days so that all the data can be grouped together by day. \n",
    "YD_rounded=[]\n",
    "\n",
    "for yd in df['Decimal_days']:\n",
    "    if np.isnan(yd) == True:\n",
    "        YD_rounded.append(float(\"NaN\"))\n",
    "    else:\n",
    "        YD_rounded.append(math.floor(yd))\n",
    "        \n",
    "df['YD_rounded']=YD_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Averaging over daily values in order to better compare with the daily model resolution.\n",
    "dfg=df.groupby(by='YD_rounded')\n",
    "df_avg=dfg.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Column that contains datetimes. \n",
    "UTC=[]\n",
    "# Maybe I can go through the days of the year bit by bit and break them down into hours. \n",
    "for yd in df_avg['Decimal_days']:\n",
    "    if np.isnan(yd) == True:\n",
    "        UTC.append(float(\"NaN\"))\n",
    "    else:\n",
    "        start = dt.datetime(1999,12,31)      \n",
    "        delta = dt.timedelta(yd)     \n",
    "        offset = start + delta\n",
    "        time=offset.replace(microsecond=0)\n",
    "        UTC.append(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'NorthBuoy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-55fa888e73c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Adding new variables for model matching.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dtUTC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUTC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mLon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPLACES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmooring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lon lat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgsw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_from_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdf_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m df_avg['SA']=gsw.SA_from_SP(df_avg['Salinity'],press,\n",
      "\u001b[0;31mKeyError\u001b[0m: 'NorthBuoy'"
     ]
    }
   ],
   "source": [
    "#Adding new variables for model matching. \n",
    "df_avg['dtUTC']=UTC\n",
    "Lon, Lat = places.PLACES[mooring]['lon lat']\n",
    "press=gsw.p_from_z(-1*df_avg['Z'],Lat)\n",
    "df_avg['SA']=gsw.SA_from_SP(df_avg['Salinity'],press,\n",
    "                       Lon,Lat)\n",
    "df_avg['CT']=gsw.CT_from_t(df_avg['SA'],df_avg['Temperature'],press)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all variables that are outside of model date range. \n",
    "df_avg=df_avg[(df_avg.dtUTC >= dt.datetime(2007,1,1))&(df_avg.dtUTC < dt.datetime(2020,1,1))]\n",
    "df_avg.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Saving data as Pickle files to be used in the summary file\n",
    "saveloc='/ocean/kflanaga/MEOPAR/ORCAData'\n",
    "with open(os.path.join(saveloc,f'daily_data_{mooring}.pkl'),'wb') as hh:\n",
    "    pickle.dump(df_avg,hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

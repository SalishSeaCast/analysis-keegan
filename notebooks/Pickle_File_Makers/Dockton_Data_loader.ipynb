{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, This script will allow me to load up and fix up the moored data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import datetime as dt\n",
    "from salishsea_tools import evaltools as et, viz_tools\n",
    "import gsw \n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import cmocean as cmo\n",
    "import scipy.interpolate as sinterp\n",
    "import pickle\n",
    "import cmocean\n",
    "import json\n",
    "import f90nml\n",
    "from collections import OrderedDict\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "fs=16\n",
    "mpl.rc('xtick', labelsize=fs)\n",
    "mpl.rc('ytick', labelsize=fs)\n",
    "mpl.rc('legend', fontsize=fs)\n",
    "mpl.rc('axes', titlesize=fs)\n",
    "mpl.rc('axes', labelsize=fs)\n",
    "mpl.rc('figure', titlesize=fs)\n",
    "mpl.rc('font', size=fs)\n",
    "mpl.rc('font', family='sans-serif', weight='normal', style='normal')\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveloc='/ocean/kflanaga/MEOPAR/mooredData'\n",
    "year=2015\n",
    "Mooring='Dockton'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{saveloc}/{Mooring}_1_1_{year}_to_12_31_{year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lat=float(df['**Legend**'][20][24:32])\n",
    "Lon=float(df['**Legend**'][20][39:49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.37611\n",
      "-122.45722\n"
     ]
    }
   ],
   "source": [
    "print(Lat)\n",
    "print(Lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[[tuple(range(0,48))]],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[[0]],inplace=True)\n",
    "df.drop(df.index[[-1]],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('index',axis=1)\n",
    "df=df.drop('Sonde_ID',axis=1)\n",
    "df=df.drop('Sonde_Batt_V',axis=1)\n",
    "df=df.drop('Logger_Batt_V',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Depth_m', 'Qual_Depth', 'Water_Temperature_degC',\n",
       "       'Qual_Water_Temperature', 'Salinity_PSU', 'Qual_Salinity',\n",
       "       'Chlorophyll_Fluorescence_ug/L', 'Qual_Chlorophyll_Fluorescence'],\n",
       "      dtype='object', name=48)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[1:-1]]=df[df.columns[1:-1]].apply(lambda col:pd.to_numeric(col, errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Z']=df['Depth_m']\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dtUTC']=pd.to_datetime(df['Date'],format='%m/%d/%Y %I:%M:%S %p')\n",
    "df['Lat']=Lat\n",
    "df['Lon']=Lon\n",
    "df['Z']=df['Depth_m']\n",
    "press=gsw.p_from_z(-1*df['Z'],df['Lat'])\n",
    "df['SA']=gsw.SA_from_SP(df['Salinity_PSU'],press,\n",
    "                       df['Lon'],df['Lat'])\n",
    "df['CT']=gsw.CT_from_t(df['SA'],df['Water_Temperature_degC'],press)\n",
    "df['Chl']=df['Chlorophyll_Fluorescence_ug/L']\n",
    "df['YD']=et.datetimeToYD(df['dtUTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=df.groupby(by='YD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_avg=dfg.mean()\n",
    "df_daily_avg['Lat']=Lat\n",
    "df_daily_avg['Lon']=Lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTC=[]\n",
    "for yd in range(0,len(dfg)):\n",
    "    start = dt.datetime(year,1,1,12,0,0)      \n",
    "    delta = dt.timedelta(yd)     \n",
    "    offset = start + delta \n",
    "    UTC.append(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_avg\n",
    "df_daily_avg['dtUTC']=UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Saving data as Pickle files to be used in the summary file\n",
    "saveloc='/ocean/kflanaga/MEOPAR/mooredData'\n",
    "with open(os.path.join(saveloc,f'data_{Mooring}_{year}.pkl'),'wb') as hh:\n",
    "    pickle.dump(df,hh)\n",
    "    \n",
    "with open(os.path.join(saveloc,f'daily_data_{Mooring}_{year}.pkl'),'wb') as hh:\n",
    "    pickle.dump(df_daily_avg,hh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

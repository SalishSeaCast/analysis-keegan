{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used to extract the King County moored data from Dockton. It loads in the King County data as as a pandas dataframe from an excel file. These excel files are not organized to work as Pandas dataframes, so a significant amount of cleaning is necessary. Several additional variables have been calculated from the data to assist in matching this data to the SalishSeaCast model output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "import datetime as dt\n",
    "from salishsea_tools import evaltools as et, viz_tools\n",
    "import gsw \n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import cmocean as cmo\n",
    "import scipy.interpolate as sinterp\n",
    "import pickle\n",
    "import cmocean\n",
    "import json\n",
    "import f90nml\n",
    "from collections import OrderedDict\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "fs=16\n",
    "mpl.rc('xtick', labelsize=fs)\n",
    "mpl.rc('ytick', labelsize=fs)\n",
    "mpl.rc('legend', fontsize=fs)\n",
    "mpl.rc('axes', titlesize=fs)\n",
    "mpl.rc('axes', labelsize=fs)\n",
    "mpl.rc('figure', titlesize=fs)\n",
    "mpl.rc('font', size=fs)\n",
    "mpl.rc('font', family='sans-serif', weight='normal', style='normal')\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveloc='/ocean/kflanaga/MEOPAR/mooredData'\n",
    "year=2018\n",
    "Mooring='Dockton'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{saveloc}/{Mooring}_1_1_{year}_to_12_31_{year}.csv',encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['**Legend**', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4',\n",
       "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9',\n",
       "       'Unnamed: 10', 'Unnamed: 11'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the Longitude and Latitude from places.\n",
    "Lon, Lat = places.PLACES[Mooring]['lon lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kflanaga/miniconda3/envs/py39/lib/python3.9/site-packages/pandas/core/indexes/base.py:4114: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  result = getitem(key)\n"
     ]
    }
   ],
   "source": [
    "#Drop the first 50 rows which contain no data whatsoever. \n",
    "df.drop(df.index[[tuple(range(0,48))]],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first row of the dataframe holds the column names of the data and must be set as equal to columns.\n",
    "df.columns=df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first and last rows of the datafame. \n",
    "df.drop(df.index[[0]],inplace=True)\n",
    "df.drop(df.index[[-1]],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Useless Columns\n",
    "df=df.drop('index',axis=1)\n",
    "df=df.drop('Sonde_ID',axis=1)\n",
    "df=df.drop('Sonde_Batt_V',axis=1)\n",
    "df=df.drop('Logger_Batt_V',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change any strings of numbers into actual numeric objects like floats\n",
    "df[df.columns[1:-1]]=df[df.columns[1:-1]].apply(lambda col:pd.to_numeric(col, errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate or Rename variables to be used in model matching. \n",
    "df['dtUTC']=pd.to_datetime(df['Date'],format='%m/%d/%Y %I:%M:%S %p')\n",
    "df['Lat']=Lat\n",
    "df['Lon']=Lon\n",
    "df['Z']=df['Depth_m']\n",
    "press=gsw.p_from_z(-1*df['Z'],df['Lat'])\n",
    "df['SA']=gsw.SA_from_SP(df['Salinity_PSU'],press,\n",
    "                       df['Lon'],df['Lat'])\n",
    "df['CT']=gsw.CT_from_t(df['SA'],df['Water_Temperature_degC'],press)\n",
    "df['Chl']=df['Chlorophyll_Fluorescence_ug/L']\n",
    "df['YD']=et.datetimeToYD(df['dtUTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of daily averages to compare to daily model output. \n",
    "dfg=df.groupby(by='YD')\n",
    "df_daily_avg=dfg.mean()\n",
    "df_daily_avg['Lat']=Lat\n",
    "df_daily_avg['Lon']=Lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column with dtUTC objects for each day. \n",
    "UTC=[]\n",
    "for yd in range(0,len(dfg)):\n",
    "    start = dt.datetime(year,1,1,12,0,0)      \n",
    "    delta = dt.timedelta(yd)     \n",
    "    offset = start + delta \n",
    "    UTC.append(offset)\n",
    "df_daily_avg['dtUTC']=UTC\n",
    "df_daily_avg=df_daily_avg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Saving data as Pickle files to be used in the summary file\n",
    "saveloc='/ocean/kflanaga/MEOPAR/mooredData'\n",
    "with open(os.path.join(saveloc,f'data_{Mooring}_{year}.pkl'),'wb') as hh:\n",
    "    pickle.dump(df,hh)\n",
    "    \n",
    "with open(os.path.join(saveloc,f'daily_data_{Mooring}_{year}.pkl'),'wb') as hh:\n",
    "    pickle.dump(df_daily_avg,hh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
